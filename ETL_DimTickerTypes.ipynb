{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (StructType, StructField, StringType,\n",
    "                               IntegerType, BooleanType, TimestampType,\n",
    "                              ArrayType, MapType, DateType)\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder.appName(\"DimTickerTypes\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.24.0\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "#load types DF\n",
    "types_df = spark \\\n",
    "        .read.option(\"recursiveFileLookup\", \"true\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .parquet(\"gs://stocks-pipeline/raw-data/ticker_types\")\n",
    "\n",
    "\n",
    "print(types_df.show())\n",
    "\n",
    "print(types_df.printSchema())\n",
    "    \n",
    "\n",
    "types_df = types_df.withColumn(\"TypeKey\", f.row_number().over(Window.orderBy('code')))\n",
    "\n",
    "types_df = types_df.withColumnRenamed(\"code\",\"TypeCode\") \\\n",
    "            .withColumnRenamed(\"description\", \"Description\") \\\n",
    "            .withColumnRenamed(\"locale\", \"Locale\")\n",
    "            \n",
    "\n",
    "types_df = types_df.fillna(value = 'Not Available', subset = [\"Description\"])\n",
    "types_df= types_df.drop(\"asset_class\")\n",
    "# persist_df = types_df.persist()\n",
    "\n",
    "# print(persist_df.show())\n",
    "    \n",
    " # create a BigQuery client and dataset reference\n",
    "client = bigquery.Client(project='noted-span-377814')\n",
    "dataset_ref = client.dataset('Stocks_DW')\n",
    "\n",
    "# create a BigQuery table and upload the data\n",
    "table_ref = dataset_ref.table('DimTickerTypes')\n",
    "job_config = bigquery.LoadJobConfig(write_disposition='WRITE_APPEND')\n",
    "job = client.load_table_from_dataframe(types_df.toPandas(), table_ref, job_config=job_config)\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
