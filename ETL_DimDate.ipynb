{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (StructType, StructField, StringType,\n",
    "                               IntegerType, BooleanType, TimestampType,\n",
    "                              ArrayType, MapType)\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DimDate\") \\\n",
    ".config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.24.0\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "start_date = '1962-01-01'\n",
    "end_date = '2023-02-28'\n",
    "\n",
    "\n",
    "# Create a PySpark DataFrame with the start and end dates\n",
    "df = spark.createDataFrame([(start_date, end_date)], [\"start_date\", \"end_date\"])\n",
    "\n",
    "# Generate a range of dates as a column\n",
    "df = df.selectExpr(\"explode(sequence(to_date(start_date), to_date(end_date))) as date_value\")\n",
    "\n",
    "df = df.select(\n",
    "    F.col('date_value'),\n",
    "    F.dayofmonth(\"date_value\").alias('day_of_month'),\n",
    "    F.date_format('date_value', 'EEEE').alias('day_of_week'),\n",
    "    F.month(\"date_value\").alias('month_number'),\n",
    "    F.date_format('date_value', 'MMMM').alias('month_name'),\n",
    "    F.year(\"date_value\").alias('year'),\n",
    "    F.quarter('date_value').alias('quarter'),    \n",
    ")\n",
    "\n",
    "result_df = df.withColumn('DateKey',  df.year * 10000 + df.month_number * 100 + df.day_of_month)\n",
    "\n",
    "# create a BigQuery client and dataset reference\n",
    "client = bigquery.Client(project='noted-span-377814')\n",
    "dataset_ref = client.dataset('Stocks_DW')\n",
    "\n",
    "\n",
    "# create a BigQuery table and upload the data\n",
    "table_ref = dataset_ref.table('DimDate')\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(write_disposition='WRITE_TRUNCATE')\n",
    "job = client.load_table_from_dataframe(result_df.toPandas(), table_ref, job_config=job_config)\n",
    "print(job.result())\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
